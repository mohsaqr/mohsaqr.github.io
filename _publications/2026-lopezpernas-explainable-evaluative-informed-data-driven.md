---
layout: publication
title: "AI, Explainable AI and Evaluative AI: Informed Data-Driven Decision-Making in Education"
authors:
  - family: "López-Pernas"
    given: "Sonsoles"
  - family: "Saqr"
    given: "Mohammed"
  - family: "Oliveira"
    given: "Eduardo"
  - family: "Song"
    given: "Yige"
year: 2026
journal: "Advanced Learning Analytics Methods"
pages: "17--39"
doi: "10.1007/978-3-031-95365-1_2"
keywords:
  - "Artificial intelligence"
  - "Education"
  - "Explainable AI"
  - "Learning analytics"
  - "Artificial Intelligence"
affiliations: "University of Eastern Finland, Joensuu, Finland; University of Melbourne, Parkville, VIC, Australia"
doc_type: "Book chapter"
selected: false
source: "both"
dimensions_url: "https://app.dimensions.ai/details/publication/pub.1194316357"
scopus_eid: "2-s2.0-105025636802"
times_cited: 2
---

Artificial Intelligence (AI) has had an immense impact in education through its ability to facilitate personalized learning experiences. However, the increasing adoption of AI systems in education has raised concerns regarding transparency and fairness. Explainable AI (XAI) emerges as a solution to address these issues, offering methods to make AI models interpretable and their decisions understandable to learners, educators, and other stakeholders. This chapter provides an overview of AI applications in education, including adaptive learning systems, profiling, and predictive modeling. Moreover, it provides an introduction to the main XAI concepts and techniques designed to ensure trustworthiness and equity in AI-driven educational environments. Enabling users to scrutinize and refine AI decisions is a necessary step in aligning technological advancements with the ethical and practical needs of education. The chapter aims to provide readers with an understanding of AI in education and XAI’s potential, serving as a foundation for the tutorials presented in the book. The chapter also discusses evaluative AI as a new perspective on XAI for decision-making in which evidence is provided against and in favor of human-made hypotheses, rather than providing explanations for the single most-likely AI outcome. © 2026 The Editor(s) (if applicable) and The Author(s).
