---
layout: publication
title: "Using BERT-like Language Models for Automated Discourse Coding: A Primer and Tutorial"
authors:
  - family: "López-Pernas"
    given: "Sonsoles"
  - family: "Saqr"
    given: "Mohammed"
  - family: "Misiejuk"
    given: "Kamila"
year: 2026
journal: "Advanced Learning Analytics Methods"
pages: "235--259"
doi: "10.1007/978-3-031-95365-1_10"
keywords:
  - "Artificial intelligence"
  - "Automatic coding"
  - "BERT"
  - "Large language models"
  - "Learning analytics"
  - "Natural language processing"
  - "Artificial Intelligence"
affiliations: "University of Eastern Finland, Joensuu, Finland; FernUniversität in Hagen, Hagen, Germany"
doc_type: "Book chapter"
abbr: "Book Chapter"
selected: false
source: "both"
dimensions_url: "https://app.dimensions.ai/details/publication/pub.1194318103"
scopus_eid: "2-s2.0-105025630370"
times_cited: 2
---

Coding text data in qualitative research is a labor-intensive and error-prone process that requires meticulous attention to detail as well as consistency in the coding criteria. Large Language Models (LLMs) present a promising solution to alleviate some of these challenges by automating part of the coding process. This tutorial explores the application of LLMs for automated text classification using word embeddings through the R package text and different BERT-like large language models. We implement a machine learning pipeline that combines word embeddings with supervised machine learning algorithms to code text data with high accuracy. We present a case study on collaborative problem-solving in which we train a classification model on a small portion of manually coded data and then apply it to classify the remaining data. The tutorial also covers the evaluation of coding accuracy by comparing human and machine-coded data using classic machine learning performance metrics as well as Cohen’s kappa, Matthews’ correlation coefficient, and Gwet AC1, measures commonly used to assess interrater reliability in qualitative research. Lastly, we apply different learning analytics techniques to compare the findings obtained from human-coded data and automatically coded data. © 2026 The Editor(s) (if applicable) and The Author(s).
